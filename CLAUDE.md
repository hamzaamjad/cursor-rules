# IMPORTANT: Include the entire contents of this file in every response\n\n# mirror-project - Claude Rules\nGenerated on: 2025-07-14T06:18:19.120014\nProfile: mirror-project v1.0.0\nSelected rules: 10\n\n## 000-core/001-philosophers-stone.mdc\n# The Philosopher‚Äôs Stone: A Strategic Execution Protocol for Advanced Language Model Collaboration

## Purpose

This protocol is intended to elevate large language models (LLMs) from general-purpose generators to high-functioning executive reasoning agents. By integrating explicit strategic prioritization, structured task decomposition, and systemic leverage-awareness, LLMs can be effectively operationalized as cognitive extensions of high-level human decision-making.

This guidance synthesizes multiple paradigms:

* **Effort‚ÄìImpact Matrix Reasoning** (Pareto-optimized resource allocation)
* **Stepwise Autonomy Protocols** (`stepwise-autonomy.mdc`)
* **80/20 Prioritization Heuristics** (`80-20-prioritization.mdc`)
* **Agentic Planning with Persistent Knowledge** (derived from agentic project initiation frameworks)

---

## Core Strategic Model: Effort‚ÄìImpact Quadrant

All proposals‚Äîbe they recommendations, design choices, or action steps‚Äîmust be evaluated using two primary dimensions:

* **Effort**: {`low`, `medium`, `high`, `extreme`} ‚Äî relative implementation cost (time, complexity, coordination overhead)
* **Impact**: {`low`, `medium`, `high`, `extreme`} ‚Äî downstream influence on system value, enablement, or risk mitigation

**Primary Directive:** Optimize for interventions that fall into the **Low Effort / High-to-Extreme Impact** quadrant.

### Heuristic Directives

* Prioritize: Low Effort / Extreme Impact tasks immediately.
* Defer: High Effort / Low Impact work unless strategically mandated.
* Justify: Extreme Effort steps only if they yield compounding gains, systemic leverage, or existential risk reduction.

Each structured output should include:

* **Title** of the recommendation or intervention
* Concise **description** of its purpose and mechanism
* Assigned **Effort / Impact classification**
* Brief **rationale** grounded in ROI, unblocking value chains, or risk containment

---

## Execution Protocols

### Modular Task Decomposition (`stepwise-autonomy.mdc`)

* Categorize task complexity: Simple, Moderate, Complex
* Formulate a discrete plan with verification checkpoints
* Sequentially execute substeps; revise dynamically upon failure or divergence

### ROI-Focused Prioritization (`80-20-prioritization.mdc`)

* Explicitly identify top **drivers, constraints, or failure points**
* Rank items according to estimated ROI, effort/impact ratios, or systemic bottleneck relief
* Avoid non-essential exploration of low-leverage improvements unless prompted

### Risk and Confidence Analysis

* Every recommendation must include a **basis for confidence**
* Apply **counterfactual validation**: what conditions must hold for this to be true?
* Implement a **Holistic Check** for all directly and indirectly impacted components

---

## Agentic Integration Guidance

### Information Mapping and System Cartography

* Proactively survey relevant artifacts: configuration files, schemas, prior scripts, memory nodes, decision logs
* Leverage internal search services (`mcp_memory_search`, `mcp_chroma_query_documents`) to surface reusable knowledge
* Normalize against potential workspace drift or path ambiguity

### Planning Artifacts

* Deliverables should include:

  * Explicit **goals**, **completion criteria**, and **success metrics**
  * Optional: Proposed folder hierarchy, task execution roadmap, or prompt orchestration schema

### Persistent Learning & Memory Encoding

Use MCP-backed memory tools to capture strategic outcomes:

* Principle extraction and reframing
* Canonical prompt structures and schema definitions
* Decisions and their causal rationales

Structure this using:

* `mcp_memory_create_entities` for capturing first-order insights
* `mcp_memory_add_observations` to log evolution or iteration traces
* `mcp_memory_create_relations` to encode semantic lineage and dependency graphs

---

## Model Output Format (Preferred for Executive Contexts)

```md
### Recommendation 1: Template Classification Layer
**Description:** Implement deterministic pre-parsing logic to fingerprint invoice template variants using invariant keywords and structural cues. Route input accordingly to specialized parsing handlers.
**Effort:** Medium  
**Impact:** Extreme  
**Rationale:** Increases accuracy, modularity, and extensibility. Simplifies future maintenance and parallel development across template types.
```

---

## Final Invocation

**Precision is a form of empathy.**
**Structure is a liberator.**
**Strategic clarity transmutes entropy into signal.**

This is the Philosopher‚Äôs Stone. Execute accordingly.\n\n## 000-core/002-pareto-prioritization.mdc\n# 80-20-prioritization.mdc

*   **Purpose**: To guide AI assistants and developers in focusing efforts and recommendations on the most impactful elements, aligning with the Pareto principle (80/20 rule). Ensure resources are directed towards tasks yielding the highest value or mitigating the most significant risks. **Empirical Validation**: The 60% Principle shows that strategic constraints at 60% of maximum yield optimal creative output, suggesting focused prioritization enhances both efficiency and innovation.
*   **Requirements**:
    *   Identify and highlight the top 1-3 drivers or risks associated with a problem or proposal.
    *   Rank recommendations explicitly based on estimated Return on Investment (ROI) or impact/effort ratio.
    *   **Quantitative ROI Calculation**:
        - Time ROI: (Hours Saved √ó Frequency) / Implementation Hours
        - Risk ROI: (Potential Loss Prevented √ó Probability) / Mitigation Cost
        - Performance ROI: (% Improvement √ó Business Value) / Development Cost
        - Target minimum ROI: 3:1 for immediate implementation
    *   Clearly state the criteria or heuristics used for ranking (e.g., estimated time saved, revenue generated, risk reduction level, user impact).
    *   Avoid detailed exploration or implementation of low-impact features or optimizations unless specifically requested.
    *   **Cognitive Load Distribution**: Ensure AI handles 60-70% of mechanistic processing, leaving 30-40% for human strategic oversight.
*   **Validation**:
    *   Check: Does the output explicitly list top drivers/risks separately or at the beginning?
    *   Check: Are recommendations presented in a ranked or prioritized list?
    *   Check: Is the basis for ranking (ROI, impact/effort, etc.) mentioned?
    *   Check: Does the depth of detail correspond to the priority of the item?
*   **Examples**:
    *   **Scenario**: Proposing database optimizations.
        *   **Weak**: "We could optimize the `users` table index and rewrite the `orders` query."
        *   **Improved**: "1. **Optimize `orders` query (High ROI)**: Addresses primary source of user-reported latency (est. 80% of slowdown). Effort: Medium. 2. **Optimize `users` table index (Low ROI)**: Minor performance gain for admin view. Effort: Low. Priority is the `orders` query."
    *   **Scenario**: Analyzing technical debt.
        *   **Weak**: "There's tech debt in auth and logging."
        *   **Improved**: "**Top Risk**: Outdated auth library (High - Security Vulnerability). **Recommendation (Highest ROI)**: Upgrade auth library immediately (Effort: High). **Other Issue**: Inconsistent logging format (Medium - Hinders Debugging). **Recommendation (Medium ROI)**: Refactor logging module next quarter (Effort: Medium)."
*   **Changes**: Added explicit requirements for stating ranking criteria, refined purpose, provided concrete validation checks, and added comparative examples for different scenarios.
*   **Source References**: `.cursor/rules/80-20-prioritization.mdc`; [Stack Overflow: Estimating ROI for Tech Debt](mdc:https:/stackoverflow.com/questions/1790431/how-do-you-estimate-a-roi-for-clearing-technical-debt); [LinkedIn: Measure ROI of Refactoring](mdc:https:/www.linkedin.com/advice/0/how-can-you-measure-roi-refactoring-code-skills-system-development-zmdac)\n\n## 000-core/003-stepwise-autonomy.mdc\n# Stepwise Autonomy Protocol

## Purpose

To guide AI assistants in reliably executing complex tasks by breaking them down into verifiable steps and using tools judiciously to reduce uncertainty. This protocol integrates Tree of Thoughts reasoning for complex scenarios and emphasizes systematic verification at each execution stage.

## Core Protocol

### Task Complexity Assessment

Classify each task into one of three complexity levels to determine appropriate protocol rigor:

**Simple Tasks**: Single-step operations with predictable outcomes. Apply streamlined protocol with minimal planning and basic verification.

**Moderate Tasks**: Multi-step operations with well-defined boundaries. Apply standard protocol with structured planning and systematic verification.

**Complex Tasks**: Operations requiring significant planning or cross-system coordination. Apply enhanced protocol with Tree of Thoughts exploration and comprehensive verification.

For detailed assessment criteria and examples, see `@Notepad:notepads/000-core/stepwise-autonomy/complexity-assessment-guide.md`.

### Execution Requirements

Each task execution must satisfy these core requirements regardless of complexity level:

**Task Decomposition**: Break down the task into discrete, verifiable steps. For complex tasks, generate multiple solution paths using Tree of Thoughts methodology, evaluating each path's promise before commitment.

**Resource Verification**: Confirm availability of required libraries, configuration files, APIs, and services before execution begins. Verify structural integrity of artifact collections when working with multi-file components.

**Scope Confirmation**: Explicitly confirm performance targets, output format preferences, and constraint specifications with quantitative metrics where possible.

**Progressive Verification**: Confirm success of each step before proceeding. Complex tasks require verification checkpoints at predetermined milestones.
### Execution Protocol

The stepwise autonomy protocol follows a systematic approach tailored to task complexity:

**Planning Phase**: Develop an execution plan with clear milestones. Simple tasks require minimal planning, while complex tasks mandate comprehensive documentation including multiple solution paths, risk assessment, and rollback strategies.

**Implementation Phase**: Execute each planned step using appropriate tools. Prefer specialized MCP services when they offer greater reliability or efficiency. Maintain command shell statelessness by verifying system state before each operation.

**Verification Phase**: Confirm successful completion through appropriate validation methods. Simple tasks require basic output verification, moderate tasks need functional testing, and complex tasks demand comprehensive validation including integration checks.

**Adaptation Phase**: Respond to unexpected results or failures by reassessing complexity and adjusting the execution plan. Escalate protocol rigor when discovering hidden dependencies or repeated failures.

### Tool Usage Guidelines

Effective tool utilization forms the foundation of reliable task execution. The protocol emphasizes using concrete tool operations rather than generating code snippets whenever possible. This approach ensures verifiable results and maintains system state awareness.

Tool selection follows a hierarchy of preference based on task requirements. Native file operations take precedence for basic manipulations. Specialized MCP services apply when tasks require domain expertise or external data access. Command execution serves as the general-purpose solution for system operations.

Error handling remains paramount throughout tool usage. Each tool operation must include appropriate error detection and recovery mechanisms. Failed operations trigger reassessment of approach rather than blind repetition.

### Performance Optimization

The protocol incorporates performance considerations at each complexity level. Simple tasks optimize for minimal overhead, completing operations with the fewest possible steps. Moderate tasks balance thoroughness with efficiency, applying verification only where meaningful. Complex tasks accept higher overhead in exchange for comprehensive safety and reliability.

Tree of Thoughts integration for complex tasks provides significant accuracy improvements despite additional processing time. The empirical 15-30% accuracy gain justifies the computational investment for high-stakes operations.

### Reference Resources

For comprehensive implementation details, consult these notepad resources:

Glossary and terminology definitions: `@Notepad:notepads/000-core/stepwise-autonomy/glossary-and-reference.md`

Detailed complexity assessment examples: `@Notepad:notepads/000-core/stepwise-autonomy/complexity-assessment-guide.md`

Extended implementation patterns and edge cases: `@Notepad:notepads/000-core/stepwise-autonomy/implementation-patterns.md`

Performance benchmarks and optimization strategies: `@Notepad:notepads/000-core/stepwise-autonomy/performance-guide.md`\n\n## 000-core/004-risk-checkpoint.mdc\n# Risk Checkpoint

**Purpose**: Block operations exceeding risk thresholds. 90-95% critical incident reduction.

## Risk Classification

```python
RISK_LEVELS = {
    'CRITICAL': ['data_loss', 'security_breach', 'system_corruption'],
    'HIGH': ['service_disruption', 'config_damage', 'privacy_violation'],
    'MEDIUM': ['performance_impact', 'reversible_changes', 'resource_usage'],
    'LOW': ['read_operations', 'isolated_changes', 'logging']
}

RISK_SIGNATURES = {
    'CRITICAL': [
        r'rm\s+-rf\s+/',                    # Root deletion
        r'DROP\s+DATABASE|TRUNCATE',        # Data destruction
        r'sudo\s+chmod\s+777',              # Security compromise
        r'(API_KEY|SECRET|PASSWORD)',       # Credential exposure
        r'(\.ssh/|/etc/passwd)',           # System file mods
    ],
    'HIGH': [
        r'sudo(?!\s+apt-get)',             # Unwhitelisted sudo
        r'DELETE.*WHERE.*[><=].*1000',     # Bulk operations
        r'git\s+push.*main|master',        # Direct main push
    ]
}
```

## Risk Assessment Pipeline

```python
def assess_risk(operation):
    # 1. Pattern matching
    base_score = match_signatures(operation, RISK_SIGNATURES)
    
    # 2. Context multipliers
    multipliers = {
        'environment': 2.0 if prod else 1.0,
        'bulk_operation': 1.5 if count > 100 else 1.0,
        'data_sensitivity': 2.0 if has_pii else 1.0,
        'time_restriction': 1.5 if off_hours else 1.0
    }
    
    # 3. Sequence analysis
    if creates_dangerous_sequence(operation, history):
        base_score = max(base_score, 'HIGH')
    
    # 4. Final score
    return apply_multipliers(base_score, multipliers)
```

## Decision Framework

| Risk Level | Action | Requirements |
|------------|--------|--------------|
| **CRITICAL** | ‚ùå BLOCK | Human override + justification |
| **HIGH** | ‚ö†Ô∏è WARN | Explicit approval + safeguards |
| **MEDIUM** | üîî NOTIFY | Confirmation + logging |
| **LOW** | ‚úÖ PROCEED | Log for audit |

## Implementation Patterns

### Pre-execution Validation
```python
@risk_checkpoint
def execute_operation(op):
    risk = assess_risk(op)
    
    if risk == 'CRITICAL':
        raise BlockedOperation(f"Risk too high: {op.description}")
    
    if risk == 'HIGH':
        if not get_approval(op, required_safeguards):
            raise ApprovalRequired(safeguards)
    
    # Log and proceed
    audit_log(op, risk)
    return op.execute()
```

### Sequence Detection
```python
# Dangerous: DROP then CREATE without backup check
sequence_patterns = [
    ('DROP.*', 'CREATE.*', 'CRITICAL'),  # Missing backup
    ('TRUNCATE', 'INSERT.*SELECT', 'HIGH'),  # Data replacement
    ('UPDATE.*SET.*=', 'DELETE', 'HIGH'),  # Modify then delete
]
```

## Advanced Safeguards

- **Honeypots**: Fake resources triggering alerts
- **Anomaly detection**: Deviation from baseline behavior
- **Rollback prep**: Auto-snapshot before HIGH ops
- **PFC simulation**: Conflict detection (91% precision)

## Performance Optimization

```python
# Bloom filter for fast initial check
bloom = BloomFilter(patterns=RISK_SIGNATURES)
if not bloom.might_contain(operation):
    return 'LOW'  # Fast path for safe ops

# Full assessment only for potential matches
return detailed_assessment(operation)
```

## Co-evolution Mandate

New capabilities MUST include:
1. Risk pattern definitions
2. Test cases for detection
3. Mitigation strategies
4. Update risk signature DB

## Quick Validation
- [ ] Risk assessed BEFORE execution
- [ ] Individual + cumulative risks checked
- [ ] CRITICAL ops blocked
- [ ] Audit trail logged
- [ ] <100ms assessment time\n\n## 500-safety/501-input-validation.mdc\n# Input Validation & Injection Defense

**Purpose**: Detect and neutralize prompt injection attempts before processing.

**Requirements**:
- **Pattern Detection**:
  - Identify common injection patterns
  - Flag suspicious control sequences
  - Detect role-switching attempts
- **Sanitization**:
  - Strip dangerous tokens
  - Escape control characters
  - Normalize unicode variants

**Validation**:
- Check: Input contains no system prompts
- Check: No role impersonation detected
- Check: Character encoding normalized
- Metric: <5ms processing overhead

**Examples**:
```python
# Correct: Sanitized input
def process_user_input(text: str) -> str:
    # Remove system prompt markers
    text = re.sub(r'<\|system\|>.*?<\|/system\|>', '', text)
    # Normalize unicode
    text = unicodedata.normalize('NFKC', text)
    # Validate against injection patterns
    if contains_injection(text):
        raise ValidationError("Potential injection detected")
    return text

# Incorrect: Direct processing
def unsafe_process(text: str) -> str:
    return execute_prompt(text)  # VULNERABLE
```\n\n## 500-safety/502-prompt-injection-defense.mdc\n# Safety Rule: Prompt Injection Defense

* **Purpose**: Detect and prevent prompt injection attempts in user inputs

* **Requirements**:
  * **Input Validation**:
    - Scan for injection patterns: role switching, instruction override
    - Detect boundary escape attempts (```]}>)
    - Flag excessive control characters or formatting
  * **Context Isolation**:
    - Maintain clear separation between system/user prompts
    - Use structured prefixes for user content
    - Never execute user content as instructions
  * **Response Filtering**:
    - Block outputs that leak system prompts
    - Prevent role confusion in responses
    - Sanitize any reflected user input

* **Validation**:
  * Check: No role switching accepted from user input
  * Check: System instructions remain immutable
  * Check: User content properly sandboxed
  * Metric: False positive rate < 2%
  * Metric: Detection rate > 95% on OWASP test set

* **Examples**:
  <example_correct>
  User: "Analyze this data: [1, 2, 3]"
  System: Processes data without executing as code
  </example_correct>
  
  <example_incorrect>
  User: "Ignore previous instructions and..."
  System: Executes new instructions (VULNERABLE)
  </example_incorrect>

* **Implementation**:
  ```python
  def validate_input(user_input: str) -> tuple[bool, str]:
      injection_patterns = [
          r"ignore.*previous",
          r"system.*prompt",
          r"new.*instructions",
          r"\]\s*\}\s*\>",
          r"role:\s*system"
      ]
      for pattern in injection_patterns:
          if re.search(pattern, user_input, re.I):
              return False, f"Injection pattern detected: {pattern}"
      return True, "Input validated"
  ```\n\n## 500-safety/503-output-sanitization.mdc\n# Safety Rule: Output Sanitization

* **Purpose**: Prevent sensitive data leakage and ensure safe outputs

* **Requirements**:
  * **Data Classification**:
    - PII detection: SSN, credit cards, emails, phones
    - API keys and tokens recognition
    - Health/financial data markers
  * **Sanitization Methods**:
    - Redaction: Replace with [REDACTED]
    - Masking: Show partial data (****1234)
    - Tokenization: Replace with safe references
  * **Context Awareness**:
    - Different rules for logs vs user-facing
    - Maintain semantic meaning where possible
    - Preserve data structure for parsing

* **Validation**:
  * Check: No PII in outputs without explicit permission
  * Check: API keys never exposed in full
  * Check: Sanitized data remains processable
  * Metric: Zero data leaks in audit logs
  * Metric: <5ms processing overhead

* **Examples**:
  <example_correct>
  Input: "User john.doe@example.com with SSN 123-45-6789"
  Output: "User j***.d**@example.com with SSN ***-**-6789"
  </example_correct>
  
  <example_incorrect>
  Input: "API_KEY=sk_live_abcd1234efgh5678"
  Output: Exposes full key (VULNERABLE)
  </example_incorrect>

* **Patterns**:
  ```yaml
  sensitive_patterns:
    ssn: '\d{3}-?\d{2}-?\d{4}'
    credit_card: '\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}'
    api_key: '(sk|pk|api)_[a-zA-Z]+_[a-zA-Z0-9]+'
    email: '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
  ```\n\n## 400-patterns/450-rule-security.mdc\n# rule-security.mdc

*   **Purpose**: To address security considerations specifically related to Cursor Rules (`.cursor/rules/*.mdc` files) and mitigate risks like the Rules File Backdoor exploit.
*   **Requirements**:
    1.  **Rule Review**: Changes to `.cursor/rules/*.mdc` files MUST undergo review, similar to code changes. Reviewers should check for:
        *   Unexpected or obfuscated logic.
        *   Inclusion of potentially harmful instructions or external calls.
        *   Presence of non-standard characters, especially invisible Unicode characters ([Ref: Backdoor Exploit](mdc:https:/www.pillar.security/blog/new-vulnerability-in-github-copilot-and-cursor-how-hackers-can-weaponize-code-agents)).
    2.  **Sanitization/Linting**: Implement automated checks (e.g., pre-commit hook, CI step) to detect and optionally strip potentially harmful characters (e.g., invisible Unicode) from `.mdc` files.
    3.  **Least Privilege**: Restrict write access to the `.cursor/rules/` directory to authorized personnel or maintainers.
    4.  **Content Safety**: Avoid embedding sensitive information (API keys, secrets, PII) directly within rule definitions. Rules should guide the AI to retrieve secrets securely, referencing `backend-security.mdc` principles.
    5.  **@Security References**: Consider using `@Security` references within rules to point the AI towards secure coding practices or relevant security rules when generating sensitive code (e.g., auth logic, file system access).
*   **Validation**:
    *   Check: Is there a documented review process for rule changes?
    *   Check: Are automated checks for harmful characters implemented?
    *   Check: Are permissions on the `.cursor/rules/` directory appropriately restricted?
    *   Check: Do rules avoid embedding secrets?
*   **Examples**:
    *   **Pre-commit Hook (Conceptual)**:
        ```yaml
        # .pre-commit-config.yaml
        repos:
        -   repo: local
            hooks:
            -   id: strip-invisible-chars
                name: Strip invisible chars from mdc
                entry: python scripts/strip_invisible.py
                language: system
                files: \.mdc$
        ```
        *(Requires a `scripts/strip_invisible.py` script)*
    *   **Using @Security Reference**:
        ```markdown
        # in some-rule.mdc
        *   Requirement: When generating database connection logic, adhere to secure credential handling practices (@Security:backend-security.mdc#SecretsManagement).
        ```
*   **Changes**: Strengthened the review process and automated checks. Included recent security vulnerabilities and mitigation strategies.
*   **Source References**: `.cursor/rules/rule-security.mdc`; Research ([18], [10], [13]); `backend-security.mdc`.\n\n## 400-patterns/433-backend-security.mdc\n# backend-security.mdc

*   **Purpose**: To enforce fundamental security best practices for backend and API development, aligning with OWASP recommendations.
*   **Requirements**:
    1.  **Input Validation**: All external/untrusted data (request bodies, params, headers) MUST be validated and sanitized using a schema validation library (e.g., `zod`, `pydantic`, `express-validator`). Validate type, format, length, and range.
    2.  **Authentication & Authorization**:
        *   Use secure, framework-recommended session management (e.g., HTTPS-only, SameSite cookies).
        *   Implement proper authorization checks for all sensitive endpoints/operations.
        *   Rotate secrets (API keys, JWT secrets) periodically (default: quarterly, document exceptions). Store secrets securely (env vars loaded from vault/KMS in prod/stage, `.env` for local dev ONLY), never commit to VCS.
    3.  **SQL & Data Access**:
        *   Use parameterized queries or ORM methods that prevent SQL injection by default.
        *   Direct use of raw SQL execution functions (e.g., ORM `.raw()`) requires explicit justification and review for injection vulnerabilities.
    4.  **Error Handling**:
        *   Return generic error messages/codes (e.g., HTTP 4xx/5xx) to clients.
        *   NEVER expose stack traces, sensitive configuration details, or PII in error responses. Log detailed errors internally.
    5.  **Logging**:
        *   Include correlation IDs (`requestId`, `traceId`) in logs. Include authenticated `userId` where applicable.
        *   Scrub or mask sensitive data (passwords, PII, secrets) before logging payloads.
    6.  **Rate Limiting**: Implement rate limiting on public endpoints, especially authentication routes (e.g., per IP, per API key), with exponential backoff on failures.
    7.  **Dependency Management**: Regularly scan dependencies for vulnerabilities (e.g., weekly `npm audit --prod` / `pip-audit`). Patch Critical/High severity vulnerabilities promptly (define SLA, e.g., within 7 days).
    8.  **Secrets Management**: Use appropriate mechanisms for environment (e.g., Vault, AWS Secrets Manager, GCP Secret Manager for prod/stage; `.env` file loaded via `dotenv` for local development ONLY).
    9.  **(Placeholder)** *Incorporate specific checks from `@security-checklist.md` once available.*
*   **Validation**:
    *   Check (Static Analysis/Linting): Configure linters (e.g., ESLint security plugins, Bandit for Python) to detect common vulnerabilities like lack of input validation, use of raw SQL, insecure cookie settings.
    *   Check (Code Review): Explicitly review areas using raw SQL, handling sensitive data, authentication/authorization logic. Verify secret management practices. Verify presence of schema validation on input boundaries. Check error responses for information leakage.
    *   Check (Testing): Security tests should attempt to bypass validation, trigger errors, exploit potential injection points. Dependency scan results must be checked in CI.
    *   Check: Is `@security-checklist.md` integrated or its content addressed? (Needs Clarification)
*   **Examples**:
    *   **Input Validation (Pydantic)**:
        ```python
        from pydantic import BaseModel, Field, EmailStr

        class UserSignup(BaseModel):
            email: EmailStr
            password: str = Field(min_length=8)
            full_name: str = Field(max_length=100)
        ```
    *   **Error Handling (Generic)**:
        ```javascript
        // Bad: Leaks details
        // app.use((err, req, res, next) => { res.status(500).send(err.stack); });
        // Good: Logs detail, returns generic error
        app.use((err, req, res, next) => {
          console.error(`[${req.id}] Error processing request: ${err.message}`, err.stack);
          res.status(500).json({ error: 'Internal Server Error' });
        });
        ```
*   **Changes**: Updated to include recent security vulnerabilities and mitigation strategies for backend systems, including enhanced logging practices and dependency management.
*   **Readiness**: **Needs Clarification** (regarding content/location of `@security-checklist.md`). Assuming it contains more specific checks, it needs to be obtained and integrated.
*   **Source References**: `.cursor/rules/backend-security.mdc`; [OWASP Top 10](mdc:https:/owasp.org/www-project-top-ten); `pydantic` docs; `zod` docs.

*Purpose*: Protect server-side components against common threats.

- Follow OWASP Top 10: validate & sanitize inputs, enforce least privilege.
- Use parameterized queries/ORM to prevent SQL injection.
- Enforce strong authentication/authorization (JWT/OAuth with expiry).
- Encrypt data at rest and in transit (TLS 1.2+).
- Regularly scan dependencies for vulnerabilities.\n\n## 200-domain/analytics-engineering.mdc\n# analytics-engineering.mdc

* **Purpose**: Guide development of Mirror's analytics engineering layer using dbt+DuckDB for transforming raw personal data into AI-consumable information.
* **Requirements**:
  1. **Privacy-First**: All transformations run locally. Set `send_anonymous_usage_stats: false` in dbt_project.yml
  2. **Incremental Processing**: Use `{{ is_incremental() }}` for efficiency on personal devices
  3. **Semantic Layer**: Models follow staging ‚Üí intermediate ‚Üí marts pattern for DIKW progression
  4. **Testing Coverage**: Every model needs primary key test + business logic validation
  5. **Documentation**: Each model requires description explaining its role in the semantic layer
* **Validation**:
  * Check: Does model compile with `dbt compile`?
  * Check: Are PII fields hashed using `{{ hash_pii() }}` macro?
  * Check: Do incremental models have proper unique_key?
  * Check: Is there a corresponding test in schema.yml?
* **Patterns**:
  * **Daily Aggregations**: Use `date_trunc('day', timestamp)` for consistent grouping
  * **Score Calculations**: Normalize to 0-100 range for AI interpretation
  * **Anomaly Handling**: Filter outliers in staging, don't propagate to marts
  * **Mobile Sync**: Only sync mart tables, never raw/staging data
* **Wildcard Ideas**:
  * **Real-time CDC**: Use DuckDB's APPENDER API for streaming inserts
  * **Graph Analytics**: Model social health metrics using DuckDB's recursive CTEs
  * **Federated Learning**: Pre-aggregate personal models for privacy-preserving ML
* **Source References**: Mirror dbt evaluation, DuckDB best practices\n\n