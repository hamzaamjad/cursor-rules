# Document Analysis Protocol

<!-- Version: 1.0.0 â€” Based on Bertin analysis task -->

* **Purpose**: Establish best practices for analyzing documents in various formats, extracting insights efficiently, and managing intermediate files.
* **Trigger**: When tasked with analyzing documents, especially in non-standard formats (.djvu, .epub, .mobi) or large text files.
* **File Format Handling**:
  - **Pre-check Tools**: Before attempting to read specialized formats, verify tool availability:
    ```bash
    # Example checks
    which djvutxt || echo "djvutxt not found. Install: brew install djvulibre"
    which pdftotext || echo "pdftotext not found. Install: brew install poppler"
    which pandoc || echo "pandoc not found. Install: brew install pandoc"
    ```
  - **Conversion Strategy**: Convert to text format when necessary for analysis
  - **Format-Specific Approaches**:
    * `.djvu`: Use `djvutxt` for text extraction
    * `.pdf`: Use `pdftotext` or `pdfgrep` for searchable PDFs
    * `.epub/.mobi`: Use `pandoc` or `ebook-convert`
* **Text Extraction Strategy**:
  - **Small Documents** (<1000 lines): Direct reading and grep searches are acceptable
  - **Large Documents** (>1000 lines):
    1. Create section index based on headers/chapters
    2. Extract table of contents if available
    3. Use systematic section-by-section extraction
    4. Build progressive summaries to avoid re-reading
  - **Search Optimization**:
    ```bash
    # Use context lines for better understanding
    grep -n -C 5 "search_term" file.txt
    # Use ripgrep for faster searches if available
    rg -C 5 "search_term" file.txt
    ```
* **Intermediate File Management**:
  - **Always Discuss**: Ask user about retention preferences for converted files
  - **Default Locations**:
    * Temporary conversions: Use system temp with descriptive names
    * Permanent conversions: Keep in same directory as source
  - **Compression**: For text files >500KB, suggest compression after extraction
  - **Naming Convention**: `[original_name]_converted.[ext]` or `[original_name]_text.txt`
* **Analysis Documentation**:
  - Document extraction method used
  - Note any content that couldn't be extracted (images, tables, special formatting)
  - Provide file size and location of any created files
* **Cleanup Protocol**:
  - List all created files at task completion
  - Offer cleanup options: keep, compress, move, or delete
  - Default to compression for large text extracts in knowledge base
* **Example Workflow**:
  ```yaml
  1. Check tools: which djvutxt
  2. Convert: djvutxt "source.djvu" > "source_text.txt"
  3. Analyze: Create index, extract sections systematically
  4. Summarize: Synthesize findings with references
  5. Cleanup: Compress if keeping (gzip source_text.txt)
  ```
* **Performance Considerations**:
  - For files >10MB, warn about processing time
  - Consider chunked processing for very large documents
  - Use streaming readers when available
* **Changes**: Initial version created after Bertin's Semiology analysis task
* **Source References**: Task retrospective from analyzing Bertin's "Semiology of Graphics"