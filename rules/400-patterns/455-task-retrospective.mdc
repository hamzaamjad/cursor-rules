---
version: 1.0.0
lastUpdated: '2025-07-06'
author: migrated
description: null
category: 400-patterns
alwaysApply: true
globs: null
performance:
  tokenReduction: 0%
  accuracyImprovement: 0%
  processingOverhead: moderate
  empiricalValidation: To be measured
dependencies:
  required: []
  recommended:
  - risk-checkpoint
  incompatible: []
conflicts: []
tags:
- patterns
- best-practices
- quality
research: []
examples: []
notes: ''
---

# Task Retrospective

* **Purpose**: To facilitate continuous improvement in AI-human collaboration by systematically reviewing completed tasks and identifying actionable insights.
* **Trigger**: Should be considered or explicitly invoked by the user upon completion of a significant task, multi-step process, or interaction segment where reflection would be valuable.
* **Requirements**:
  1. **Review Conversation**: Briefly analyze the preceding interaction related to the completed task.
  2. **Identify Successes**: List 1-3 key actions, interpretations, or outcomes that were handled effectively or efficiently.
  3. **Identify Challenges**: List 1-3 specific instances where actions were incorrect, inefficient, required clarification/correction, or led to suboptimal outcomes. Pinpoint the root cause if possible (e.g., ambiguity in request, misunderstanding of context, limitation in capabilities, rule gap).
  4. **Derive Actionable Takeaways**: Formulate concrete suggestions for future interactions. These might include:
     * Improved communication strategies (e.g., phrasing requests, providing context).
     * Refinements to AI behavior (e.g., asking specific types of clarifying questions, performing certain checks).
     * Identification of knowledge gaps or context limitations.
     * Reflection on problem-solving approaches: How were unexpected challenges or tool limitations addressed? Was iterative refinement or resilient troubleshooting demonstrated, and what can be learned from that process?
  5. **Propose Systemic Updates (If Applicable)**:
     * Suggest modifications to existing `.cursor/rules/*.mdc` files based on the takeaways.
     * Propose the creation of new rules if a recurring pattern or significant gap is identified.
     * Suggest adding relevant information (patterns, context, preferences) to persistent memory (Knowledge Graph/Chroma) to prevent recurrence of issues.
* **Validation**:
  * Check: Does the output include both positive and negative points from the interaction?
  * Check: Are the takeaways specific and actionable?
  * Check: Does the output consider or propose updates to rules or memory if relevant?
* **Examples**:
  * *See conversation preceding the creation of this rule (MCP server integration task) for a detailed example.*
  * **Brief Example:** "Task: Refactor module X. *Success:* Correctly identified and refactored target functions. *Challenge:* Initially missed updating a related configuration file, requiring user correction. *Takeaway:* Improve `stepwise-autonomy`'s 'Holistic Check' to explicitly look for config files related to refactored modules. *Update:* Proposed edit to `stepwise-autonomy.mdc`."
* **Changes**: Initial version.
* **Source References**: Based on collaborative review of MCP server integration task.