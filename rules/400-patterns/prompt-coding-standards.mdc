---
description: 
globs: 
alwaysApply: true
---
# prompt-coding-standards.mdc

*   **Purpose**: To provide guidance on incorporating coding standards and best practices into prompt output specifications.
*   **Requirements**:
    1. When defining output specifications for code generation prompts, refer to the relevant coding standards and best practices for the target programming language (e.g., `python-clean-code.mdc` for Python).
    2. Ensure that the output specifications include requirements for code formatting, naming conventions, documentation, error handling, and logging, as applicable.
    3. Provide examples of code snippets that adhere to the specified coding standards to guide the model's output.
    4. For any prompt that involves model selection, recommendation, or configuration, explicitly reference the official Cursor model documentation (https://docs.cursor.com/settings/models) to ensure up-to-date and accurate guidance.
    5. **Security Considerations**:
        *   Ensure prompts do not expose sensitive information or encourage insecure coding practices.
        *   Validate input data and sanitize outputs to prevent injection vulnerabilities.
*   **Validation**:
    *   Check: Do the output specifications reference the relevant coding standards and best practices?
    *   Check: Are the requirements for code formatting, naming conventions, documentation, error handling, and logging clearly specified?
    *   Check: Are examples of code snippets that adhere to the specified coding standards provided?
    *   Check: For prompts involving model selection, is https://docs.cursor.com/settings/models referenced?
*   **Changes**: Incorporated new standards for prompt engineering, especially for LLMs, to ensure consistency and effectiveness. Updated references to the latest Cursor documentation.
*   **Source References**: Created based on the task retrospective of the `autopilot_buildout.json` prompt optimization task.
